{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "show_intermediate_results = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "playlists = pl.scan_parquet('../processed_data/data_playlist_metadata.parquet')\n",
    "playlist_tracks = pl.scan_parquet('../processed_data/data_playlist_songs.parquet')\n",
    "tracks = pl.scan_parquet('../processed_data/data_song_metadata.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists.collect() if show_intermediate_results else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_tracks.collect() if show_intermediate_results else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.collect()  if show_intermediate_results else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(expr: pl.Expr) -> pl.Expr:\n",
    "    return expr.str.to_lowercase().str.split(' ')\n",
    "\n",
    "def tokenize_unique(expr: pl.Expr) -> pl.Expr:\n",
    "    return tokenize(expr)\\\n",
    "        .list.filter(pl.element().ne(''))\\\n",
    "        .list.unique(maintain_order=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Tokenize the playlist names by splitting on whitespaces.\n",
    "\n",
    "We currently turn every word into its own separate keyword term.\n",
    "As a later optimization, it might make sense to treat words most often\n",
    "occuring together (e.g. `late night`) to make the output more useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_tokenized = playlists.select(\n",
    "    pl.col('playlist.id'),\n",
    "    pl.col('playlist.name'),\n",
    "    pl.col('playlist.name').pipe(tokenize_unique).alias('unique_terms'),\n",
    ")\n",
    "\n",
    "playlists_tokenized.collect(engine='streaming') if show_intermediate_results else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Aggregate over playlist terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_playlists_tokenized = playlists_tokenized\\\n",
    "    .explode('unique_terms')\\\n",
    "    .rename({'unique_terms': 'term'})\n",
    "\n",
    "exploded_playlists_tokenized.limit(100).collect(engine='streaming') if show_intermediate_results else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = exploded_playlists_tokenized\\\n",
    "    .group_by('term')\\\n",
    "    .agg(pl.col('term').count().alias('playlist_count'))\\\n",
    "    .sort('playlist_count', descending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review query plan for potential performance/memory problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens.show_graph(plan_stage='physical', engine='streaming', optimized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens.filter(pl.col('playlist_count').ge(100)).collect(engine='streaming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV\n",
    "# tokens.filter(pl.col('playlist_count').ge(20)).sink_csv('playlist_keywords.csv', engine='streaming')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following discoveries where made when manually reviewing the CSV data:\n",
    "\n",
    "- Also split on & remove common punctuation (`(`, `)`, `[`, `]`,`:`, `#` etc.)\n",
    "- Remove certain common words that do not provide any information:\n",
    "  - on\n",
    "  - by\n",
    "  - with\n",
    "  - at\n",
    "  - and\n",
    "  - a\n",
    "  - I\n",
    "  - ...\n",
    "- Unify `90's`/`90s` etc.\n",
    "- Unify `bday`/`birthday`/`b-day` etc.\n",
    "- Check correlations between consecutive words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword <=> Song correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore tokens that appear only a few types to reduce the size of the `join`/`group_by`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens\\\n",
    "    .filter(pl.col('playlist_count').le(5))\\\n",
    "    .group_by(pl.col('playlist_count').alias('max_playlist_count'))\\\n",
    "    .agg(pl.col('playlist_count').count().alias('num_terms'))\\\n",
    "    .sort('max_playlist_count')\\\n",
    "    .collect(engine='streaming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_tokens = tokens\\\n",
    "    .filter(pl.col('playlist_count').ge(5))\\\n",
    "    .collect(engine='streaming')\n",
    "\n",
    "track_keywords = playlist_tracks\\\n",
    "    .join(exploded_playlists_tokenized.join(relevant_tokens.lazy(), how='semi', on='term'), how='inner', on='playlist.id')\\\n",
    "    .group_by('track.id', 'term')\\\n",
    "    .agg(pl.col('term').count().alias('playlist_count'))\n",
    "\n",
    "track_keywords.limit(50).collect(engine='streaming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = track_keywords\\\n",
    "    .sort('track.id', 'playlist_count', 'term')\\\n",
    "    .group_by('track.id')\\\n",
    "    .agg(pl.col('term').sort_by('playlist_count', descending=True).head(30))\n",
    "\n",
    "q.show_graph(plan_stage='physical', engine='streaming', optimized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = track_keywords\\\n",
    "#     .sort('track.id', 'playlist_count', 'term')\\\n",
    "#     .group_by('track.id')\\\n",
    "#     .agg(pl.col('term').first())\n",
    "\n",
    "q = track_keywords.count()\n",
    "\n",
    "# q.show_graph(plan_stage='physical', engine='streaming', optimized=True)\n",
    "\n",
    "q.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
